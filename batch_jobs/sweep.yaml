program: train.py
method: grid
metric:
  name: val/loss
  goal: minimize
parameters:
  task:
    values:
      # - non_qa_to_qa
      # - hr_to_lr_noinst
      # - hr_to_lr
      # - hr_to_lr_dev
      # - hr_to_lr_dev_mcq
      # - non_nli_to_nli
      # - non_paraphrase_to_paraphrase
      # - non_class_to_class
      # - qa_to_qa
      # - class_to_class
      # - wdc-v3-cluster200
      # - cluster50_top10clusters_max20percluster
      # - wdc4-clusters50
      # - wdc4-clusters200
      - wdc4-clusters500
      # - wdc4-clusters2000
      # - artificialdatasets_yesno2yesno
      # - artificialdatasets_sentence2yesno
      # - artificialdatasets_sentence2word
      # - artificialdatasets_word2sentence
      # - artificialdatasets_word2word
      # - wdc-v3-flashcards
      # - |-
      #   hr_to_lr_dev
      #   wdc4-clusters500;is_cluster_dataset:1;cluster_idxs:249,272,17,139,306;max_tasks_per_cluster:50
  # task_ratios:
  #   values:
  #     - 1.0,0.0
  #     - 0.8,0.2
  #     - 0.6,0.4
  #     - 0.4,0.6
  #     - 0.2,0.8
  #     - 0.0,1.0
  # target_num_examples:
  #   values: [8000]
  wandb_tags:
    values: ['best-in-sweep,use-demos']
  max_examples_per_task:
    values: [200]
  gradient_accumulation_steps:
    values: [1]
  lr:
    values: [5e-6]
  shuffle:
    values: [1]
  shuffle_examples_seed:
    values: [0,1,2]
  label_smoothing:
    values: [0.0]
  debug_data_order:
    values: [0]
  num_training_steps:
    values: [50000]
  repeat_batch:
    values: [1]
  verbose_train:
    values: [0]
  log_period:
    values: [2000]
  test_tasks:
    values: ['all_tasks_test']
  max_examples_per_test:
    values: [100]
  use_demonstrations:
    values: [0, 1]
  # swap_input_output:
    # values: [0, 1]
  # predict_last_word:
  #   values: [0, 1]
  # use_random_label:
  #   values: [0, 1]
  is_cluster_dataset:
    values: [1]
  cluster_idxs:
    values:
      - '249,272,17,139,306'
  #     # - '249,272,17,139,306,175,307,285,243,134'
  #     # - '249,272,17,139,306,175,307,285,243,134,198,212,180,209,305,251,270,178,163,200'
  max_tasks_per_cluster:
    values: [200]
  # gpt2:
  #   values: ["gpt2-xl"]
  # init_checkpoint:
  #   values:
  #     - /home/jc11431/git/MetaICL/checkpoints/metaicl/multistage-wdcv4-hrtolrdev/mix_stage_1/model18635380_1-best_dev_score.pt
  #     - /home/jc11431/git/MetaICL/checkpoints/metaicl/multistage-wdcv4-hrtolrdev/mix_stage_1/model18635380_4-best_dev_score.pt
command:
  - python
  - ${program}
  - ${args}