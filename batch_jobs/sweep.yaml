program: train.py
method: grid
metric:
  name: val/loss
  goal: minimize
parameters:
  task:
    values:
      # - non_qa_to_qa
      # - hr_to_lr_noinst
      # - hr_to_lr
      # - hr_to_lr_dev
      # - non_nli_to_nli
      # - non_paraphrase_to_paraphrase
      # - non_class_to_class
      # - qa_to_qa
      # - class_to_class
      # - wdc-v3-cluster200
      # - cluster50_top10clusters_max20percluster
      - wdc4-clusters50
      # - wdc4-clusters200
      # - wdc4-clusters500
      # - wdc4-clusters2000
  wandb_tags:
    values: ['best-in-sweep,wdc-v4-best-clusters50']
  max_examples_per_task:
    values: [200]
  gradient_accumulation_steps:
    values: [1]
  lr:
    values: [5e-6]
  shuffle:
    values: [1]
  shuffle_examples_seed:
    values: [0]
  label_smoothing:
    values: [0.0]
  debug_data_order:
    values: [0]
  num_training_steps:
    values: [50000]
  repeat_batch:
    values: [1]
  verbose_train:
    values: [0]
  log_period:
    values: [2000]
  test_tasks:
    values: ['all_tasks_test']
  is_cluster_dataset:
    values: [1]
  cluster_idxs:
    values:
      - '6,3,21,13,2,12,17,10,18,16'
      - '6,3,21,13,2'
      - '48,6,13,47,21,42,17,10,25,33'
      - '48,6,13,47,21'
  max_tasks_per_cluster:
    values: [20,50]
  # gpt2:
  #   values: ["gpt2-xl", "gpt2-large"]
  # init_checkpoint:
  #   values: ['checkpoints/metaicl/wdc-v2_cluster_t200/metaicl_m200-best_task_dev_score.pt']
command:
  - python
  - ${program}
  - ${args}