program: train.py
method: grid
metric:
  name: val/loss
  goal: minimize
parameters:
  task:
    values:
      # - non_qa_to_qa
      # - hr_to_lr_noinst
      # - hr_to_lr
      # - hr_to_lr_dev
      # - hr_to_lr_dev_mcq
      # - non_nli_to_nli
      # - non_paraphrase_to_paraphrase
      # - non_class_to_class
      # - qa_to_qa
      # - class_to_class
      # - wdc-v3-cluster200
      # - cluster50_top10clusters_max20percluster
      # - wdc4-clusters50
      # - wdc4-clusters200
      # - wdc4-clusters500
      # - wdc4-clusters2000
      # - artificialdatasets_yesno2yesno
      # - artificialdatasets_sentence2yesno
      # - artificialdatasets_sentence2word
      # - artificialdatasets_word2sentence
      # - artificialdatasets_word2word
      # - wdc-v3-flashcards
      # - |-
      #   hr_to_lr_dev
      #   wdc4-clusters500;is_cluster_dataset:1;cluster_idxs:249,272,17,139,306;max_tasks_per_cluster:50
      # - wdc-v4
      - wdc-v5
      # - wdc-v5-all_delims
      # - wdc5-clusters5
      # - wdc5-clusters15
      # - wdc5-clusters50
      # - wdc5-clusters200
  # task_ratios:
  #   values:
  #     - 1.0,0.0
  #     - 0.8,0.2
  #     - 0.6,0.4
  #     - 0.4,0.6
  #     - 0.2,0.8
  #     - 0.0,1.0
  # target_num_examples:
  #   values: [8000]
  wandb_tags:
    values: ['wdc-v5_scaling-big']
  max_tasks:
    values: [200, 1000, 5000, 25000]
  # max_examples_per_task:
  #   values: [200]
  batch_size:
    values: [4]
  gradient_accumulation_steps:
    values: [1]
  lr:
    values: [5e-6]
  shuffle:
    values: [1]
  shuffle_examples_seed:
    values: [0]
  label_smoothing:
    values: [0.0]
  debug_data_order:
    values: [0]
  num_training_steps:
    values: [1000000]
  save_period:
    values: [10000]
  log_period:
    values: [10000]
  repeat_batch:
    values: [1]
  verbose_train:
    values: [0]
  test_tasks:
    values: ['all_tasks_cleandev']
  test_batch_size:
    values: [16]
  max_examples_per_test:
    values: [100]
  # use_demonstrations:
  #   values: [0, 1]
  # swap_input_output:
    # values: [0, 1]
  # predict_last_word:
  #   values: [0, 1]
  # use_random_label:
  #   values: [0, 1]
  # is_cluster_dataset:
  #   values: [1]
  # max_tasks_per_cluster:
  #   values: [1000]
  # cluster_idxs:
  #   values:
  #     - '1' # wdc5-clusters5best1
  #     - '1,12,9' # wdc5-clusters15best3
  #     - '8,15,36,20,17,30,40,38,24,39' # wdc5-clusters50best10
  #     # - '249,272,17,139,306'
  #     # - '249,272,17,139,306,175,307,285,243,134'
  #     # - '249,272,17,139,306,175,307,285,243,134,198,212,180,209,305,251,270,178,163,200'
  #     - '0'
  #     - '1'
  #     - '2'
  #     - '3'
  #     - '4'
  #     - '5'
  #     - '6'
  #     - '7'
  #     - '8'
  #     - '9'
  #     - '10'
  #     - '11'
  #     - '12'
  #     - '13'
  #     - '14'
  #     - '15'
  #     - '16'
  #     - '17'
  #     - '18'
  #     - '19'
  #     - '20'
  #     - '21'
  #     - '22'
  #     - '23'
  #     - '24'
  #     - '25'
  #     - '26'
  #     - '27'
  #     - '28'
  #     - '29'
  #     - '30'
  #     - '31'
  #     - '32'
  #     - '33'
  #     - '34'
  #     - '35'
  #     - '36'
  #     - '37'
  #     - '38'
  #     - '39'
  #     - '40'
  #     - '41'
  #     - '42'
  #     - '43'
  #     - '44'
  #     - '45'
  #     - '46'
  #     - '47'
  #     - '48'
  #     - '49'
  # gpt2:
  #   values: ["gpt2-xl"]
  # init_checkpoint:
  #   values:
  #     - /home/jc11431/git/MetaICL/checkpoints/metaicl/multistage-wdcv4-hrtolrdev/mix_stage_1/model18635380_1-best_dev_score.pt
  #     - /home/jc11431/git/MetaICL/checkpoints/metaicl/multistage-wdcv4-hrtolrdev/mix_stage_1/model18635380_4-best_dev_score.pt
command:
  - python
  - ${program}
  - ${args}